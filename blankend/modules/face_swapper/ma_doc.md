```markdown
# MatAnyone ONNX æ¨¡å‹è¯´æ˜æ–‡æ¡£

## ğŸ“‹ æ¨¡å‹æ¦‚è¿°

**æ¨¡å‹åç§°ï¼š** MatAnyone (Fixed ONNX Version)  
**æ¨¡å‹æ–‡ä»¶ï¼š** `matanyone_fixed.onnx`  
**æ¨¡å‹ç±»å‹ï¼š** å›¾åƒæŠ å›¾ / å‰æ™¯åˆ†å‰² (Image Matting / Foreground Segmentation)  
**æ¡†æ¶ç‰ˆæœ¬ï¼š** ONNX Opset 18  
**æ¨ç†å¼•æ“ï¼š** ONNX Runtime (æ”¯æŒ CUDA / CPU)  
**æ¨¡å‹å¤§å°ï¼š** ~XX MBï¼ˆæ ¹æ®å®é™…æ–‡ä»¶å¤§å°å¡«å†™ï¼‰

---

## ğŸ¯ æ¨¡å‹èƒ½åŠ›

### æ ¸å¿ƒåŠŸèƒ½
- âœ… **å®æ—¶è§†é¢‘æŠ å›¾**ï¼šé«˜æ€§èƒ½çš„å‰æ™¯/èƒŒæ™¯åˆ†ç¦»
- âœ… **äººç‰©ä¸»ä½“æå–**ï¼šç²¾ç¡®è¯†åˆ«äººç‰©è½®å»“å’Œè¾¹ç¼˜ç»†èŠ‚
- âœ… **å‚è€ƒå¸§æœºåˆ¶**ï¼šåˆ©ç”¨é¦–å¸§ä¿¡æ¯æå‡åç»­å¸§çš„ç¨³å®šæ€§
- âœ… **ç«¯åˆ°ç«¯æ¨ç†**ï¼šæ— éœ€é¢å¤–çš„é¢„å¤„ç†æˆ–åå¤„ç†æ¨¡å‹

### é€‚ç”¨åœºæ™¯
- ğŸ¬ **è§†é¢‘ä¼šè®®èƒŒæ™¯æ›¿æ¢**
- ğŸ® **æ¸¸æˆç›´æ’­è™šæ‹ŸèƒŒæ™¯**
- ğŸ“¸ **è¯ä»¶ç…§èƒŒæ™¯å¤„ç†**
- ğŸ¨ **è§†é¢‘ç‰¹æ•ˆåˆ¶ä½œ**
- ğŸ–¼ï¸ **ç”µå•†äº§å“å›¾æŠ å›¾**

### æ€§èƒ½æŒ‡æ ‡
| æŒ‡æ ‡ | æ•°å€¼ |
|------|------|
| è¾“å…¥åˆ†è¾¨ç‡ | 512 Ã— 512 (å›ºå®š) |
| æ¨ç†é€Ÿåº¦ (RTX 3090) | ~XX ms/frame |
| æ¨ç†é€Ÿåº¦ (CPU) | ~XX ms/frame |
| å†…å­˜å ç”¨ | ~XX MB |
| ç²¾åº¦ | Float32 |

---

## ğŸ“¥ æ¨¡å‹è¾“å…¥è§„æ ¼

### è¾“å…¥å¼ é‡æ¸…å•

| è¾“å…¥åç§° | å½¢çŠ¶ | æ•°æ®ç±»å‹ | å€¼åŸŸ | è¯´æ˜ |
|----------|------|----------|------|------|
| **`image`** | `[batch, 3, 512, 512]` | `float32` | `[0.0, 1.0]` | å¾…å¤„ç†çš„ RGB å›¾åƒ |
| **`ref_sensory`** | `[batch, 1, 256, 32, 32]` | `float32` | ä»»æ„æµ®ç‚¹æ•° | å‚è€ƒæ„ŸçŸ¥ç‰¹å¾å›¾ |
| **`ref_mask`** | `[batch, 1, 512, 512]` | `float32` | `[0.0, 1.0]` | å‚è€ƒé®ç½©å›¾ |

---

### 1ï¸âƒ£ `image` - ä¸»è¾“å…¥å›¾åƒ

#### æ ¼å¼è¦æ±‚
```python
å½¢çŠ¶ï¼š[batch_size, 3, 512, 512]
é€šé“é¡ºåºï¼šRGB (æ³¨æ„ï¼šä¸æ˜¯ BGRï¼)
æ•°æ®ç±»å‹ï¼šnp.float32
å€¼åŸŸï¼š[0.0, 1.0] (å·²å½’ä¸€åŒ–)
```

#### é¢„å¤„ç†æ­¥éª¤
```python
import cv2
import numpy as np

# 1. è¯»å– BGR å›¾åƒ
img_bgr = cv2.imread("input.jpg")

# 2. Resize åˆ° 512Ã—512
img_resized = cv2.resize(img_bgr, (512, 512))

# 3. BGR â†’ RGB
img_rgb = cv2.cvtColor(img_resized, cv2.COLOR_BGR2RGB)

# 4. å½’ä¸€åŒ–åˆ° [0, 1]
img_normalized = img_rgb.astype(np.float32) / 255.0

# 5. HWC â†’ NCHW
img_tensor = np.transpose(img_normalized, (2, 0, 1))  # (512, 512, 3) â†’ (3, 512, 512)
img_tensor = np.expand_dims(img_tensor, axis=0)        # (3, 512, 512) â†’ (1, 3, 512, 512)
```

#### âš ï¸ å¸¸è§é”™è¯¯
- âŒ **é”™è¯¯ 1ï¼šæœªè½¬æ¢ BGRâ†’RGB**
  ```python
  # é”™è¯¯ç¤ºä¾‹
  img_tensor = img_bgr / 255.0  # è¿˜æ˜¯ BGRï¼
  ```
  
- âŒ **é”™è¯¯ 2ï¼šå€¼åŸŸé”™è¯¯**
  ```python
  # é”™è¯¯ç¤ºä¾‹
  img_tensor = img_rgb.astype(np.float32)  # èŒƒå›´æ˜¯ [0, 255]ï¼Œæœªå½’ä¸€åŒ–ï¼
  ```

- âŒ **é”™è¯¯ 3ï¼šç»´åº¦é¡ºåºé”™è¯¯**
  ```python
  # é”™è¯¯ç¤ºä¾‹
  img_tensor = img_rgb / 255.0  # å½¢çŠ¶æ˜¯ (512, 512, 3)ï¼Œç¼ºå°‘ batch ç»´åº¦ï¼
  ```

---

### 2ï¸âƒ£ `ref_sensory` - å‚è€ƒæ„ŸçŸ¥ç‰¹å¾

#### æ ¼å¼è¦æ±‚
```python
å½¢çŠ¶ï¼š[batch_size, 1, 256, 32, 32]
æ•°æ®ç±»å‹ï¼šnp.float32
å€¼åŸŸï¼šä»»æ„æµ®ç‚¹æ•°
```

#### åˆå§‹åŒ–æ–¹å¼

**æ–¹å¼ Aï¼šé›¶åˆå§‹åŒ–ï¼ˆæ¨èï¼Œç”¨äºé¦–å¸§ï¼‰**
```python
ref_sensory = np.zeros((1, 1, 256, 32, 32), dtype=np.float32)
```

**æ–¹å¼ Bï¼šä½¿ç”¨ä¸Šä¸€å¸§çš„è¾“å‡ºï¼ˆé«˜çº§ç”¨æ³•ï¼‰**
```python
# å¦‚æœæ¨¡å‹è¾“å‡ºåŒ…å« sensory ç‰¹å¾ï¼ˆå½“å‰ç‰ˆæœ¬ä¸æ”¯æŒï¼‰
# ref_sensory = previous_output['sensory']
```

#### ä½œç”¨æœºåˆ¶
- ğŸ” **é¦–å¸§å»ºç«‹åŸºå‡†**ï¼šæ¨¡å‹å†…éƒ¨æå–å›¾åƒçš„æ·±å±‚ç‰¹å¾
- ğŸ”„ **åç»­å¸§å‚è€ƒ**ï¼šåˆ©ç”¨é¦–å¸§ç‰¹å¾è¾…åŠ©åˆ†å‰²
- ğŸ“Œ **ç¨³å®šæ€§ä¿è¯**ï¼šå‡å°‘å¸§é—´æŠ–åŠ¨å’Œé—ªçƒ

#### âš ï¸ æ³¨æ„äº‹é¡¹
- å¯¹äº**é™æ€å›¾åƒ**æˆ–**é¦–å¸§**ï¼Œä½¿ç”¨é›¶åˆå§‹åŒ–
- å¯¹äº**è§†é¢‘åºåˆ—**ï¼Œæ‰€æœ‰å¸§å…±äº«é¦–å¸§çš„ `ref_sensory`
- **åœºæ™¯åˆ‡æ¢**æ—¶éœ€è¦é‡æ–°åˆå§‹åŒ–

---

### 3ï¸âƒ£ `ref_mask` - å‚è€ƒé®ç½©

#### æ ¼å¼è¦æ±‚
```python
å½¢çŠ¶ï¼š[batch_size, 1, 512, 512]
æ•°æ®ç±»å‹ï¼šnp.float32
å€¼åŸŸï¼š[0.0, 1.0]
```

#### åˆå§‹åŒ–æ–¹å¼

**æ–¹å¼ Aï¼šé›¶åˆå§‹åŒ–ï¼ˆæ¨èï¼Œç”¨äºé¦–å¸§ï¼‰**
```python
ref_mask = np.zeros((1, 1, 512, 512), dtype=np.float32)
```

**æ–¹å¼ Bï¼šä½¿ç”¨ä¸Šä¸€å¸§çš„ Alpha è¾“å‡ºï¼ˆå¯é€‰ï¼‰**
```python
# å¦‚æœå¸Œæœ›é€å¸§æ›´æ–°å‚è€ƒ
ref_mask = previous_alpha[:, 1:2, :, :]  # å–å‰æ™¯é€šé“
```

#### ä½œç”¨æœºåˆ¶
- ğŸ¯ **ç©ºé—´å…ˆéªŒ**ï¼šå‘Šè¯‰æ¨¡å‹å‰æ™¯å¤§è‡´ä½ç½®
- ğŸ”„ **æ—¶åºä¼ é€’**ï¼šåˆ©ç”¨å‰å¸§ç»“æœä¼˜åŒ–å½“å‰å¸§
- ğŸ¨ **è¾¹ç¼˜ä¼˜åŒ–**ï¼šæ”¹å–„ç»†èŠ‚å’Œè¾¹ç¼˜è´¨é‡

#### ä½¿ç”¨ç­–ç•¥å¯¹æ¯”

| ç­–ç•¥ | `ref_mask` æ›´æ–°æ–¹å¼ | ä¼˜ç‚¹ | ç¼ºç‚¹ | é€‚ç”¨åœºæ™¯ |
|------|---------------------|------|------|----------|
| **å›ºå®šé¦–å¸§** | å§‹ç»ˆä¸ºé›¶ | ç¨³å®šï¼Œæ— æ¼‚ç§» | å¯¹è¿åŠ¨ä¸æ•æ„Ÿ | é™æ€åœºæ™¯ã€è¯ä»¶ç…§ |
| **é€å¸§æ›´æ–°** | ä½¿ç”¨ä¸Šä¸€å¸§è¾“å‡º | è·Ÿè¸ªè¿åŠ¨ | å¯èƒ½ç´¯ç§¯è¯¯å·® | åŠ¨æ€è§†é¢‘ã€è¿ç»­åŠ¨ä½œ |
| **å‘¨æœŸé‡ç½®** | æ¯ N å¸§é‡ç½®ä¸ºé›¶ | å¹³è¡¡ç¨³å®šä¸é€‚åº” | å®ç°å¤æ‚ | é•¿è§†é¢‘å¤„ç† |

---

## ğŸ“¤ æ¨¡å‹è¾“å‡ºè§„æ ¼

### è¾“å‡ºå¼ é‡æ¸…å•

| è¾“å‡ºåç§° | å½¢çŠ¶ | æ•°æ®ç±»å‹ | å€¼åŸŸ | è¯´æ˜ |
|----------|------|----------|------|------|
| **`alpha`** | `[batch, 2, 512, 512]` | `float32` | `[0.0, 1.0]` | åŒé€šé“æ¦‚ç‡å›¾ |

---

### `alpha` - åˆ†å‰²æ¦‚ç‡å›¾

#### æ ¼å¼è¯´æ˜
```python
å½¢çŠ¶ï¼š[batch_size, 2, 512, 512]
é€šé“ 0ï¼šèƒŒæ™¯æ¦‚ç‡ (Background Probability)
é€šé“ 1ï¼šå‰æ™¯æ¦‚ç‡ (Foreground Probability)
æ•°æ®ç±»å‹ï¼šnp.float32
å€¼åŸŸï¼š[0.0, 1.0]
```

#### æå–æ–¹å¼

**æå–å‰æ™¯é®ç½©**
```python
# æ¨ç†
outputs = session.run(None, inputs)
alpha_output = outputs[0]  # shape: (1, 2, 512, 512)

# æå–å‰æ™¯æ¦‚ç‡
foreground_prob = alpha_output[0, 1]  # shape: (512, 512)

# æå–èƒŒæ™¯æ¦‚ç‡
background_prob = alpha_output[0, 0]  # shape: (512, 512)

# éªŒè¯ï¼šä¸¤è€…ä¹‹å’Œåº”è¯¥æ¥è¿‘ 1.0
assert np.allclose(foreground_prob + background_prob, 1.0)
```

#### åå¤„ç†ç¤ºä¾‹

**1. äºŒå€¼åŒ–é®ç½©**
```python
# é˜ˆå€¼åŒ–ï¼ˆç¡¬è¾¹ç¼˜ï¼‰
threshold = 0.5
binary_mask = (foreground_prob > threshold).astype(np.uint8) * 255
```

**2. Alpha åˆæˆï¼ˆè½¯è¾¹ç¼˜ï¼‰**
```python
# Resize å›åŸå§‹å°ºå¯¸
alpha = cv2.resize(foreground_prob, (orig_width, orig_height))

# æ‰©å±•åˆ° 3 é€šé“
alpha_3c = np.stack([alpha, alpha, alpha], axis=-1)

# åˆæˆç»¿å¹•
foreground = img_original.astype(np.float32)
background = np.zeros_like(img_original)
background[:, :] = (0, 255, 0)  # BGR æ ¼å¼ç»¿è‰²

result = foreground * alpha_3c + background * (1 - alpha_3c)
result = np.clip(result, 0, 255).astype(np.uint8)
```

**3. å››é€šé“ PNG è¾“å‡º**
```python
# åˆ›å»º RGBA å›¾åƒ
img_rgba = np.dstack([img_rgb, (alpha * 255).astype(np.uint8)])

# ä¿å­˜é€æ˜èƒŒæ™¯å›¾
from PIL import Image
Image.fromarray(img_rgba).save("output.png")
```

#### è´¨é‡ä¼˜åŒ–

**è¾¹ç¼˜ç¾½åŒ–**
```python
# é«˜æ–¯æ¨¡ç³ŠæŸ”åŒ–è¾¹ç¼˜
alpha_smooth = cv2.GaussianBlur(foreground_prob, (5, 5), 2.0)
```

**å½¢æ€å­¦å¤„ç†**
```python
# å»é™¤å°å™ªç‚¹
kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (5, 5))
alpha_clean = cv2.morphologyEx(foreground_prob, cv2.MORPH_OPEN, kernel)
alpha_clean = cv2.morphologyEx(alpha_clean, cv2.MORPH_CLOSE, kernel)
```

---

## âš™ï¸ æ¨¡å‹ç‰¹å®šè¦æ±‚

### 1ï¸âƒ£ åˆ†è¾¨ç‡é™åˆ¶

#### å›ºå®šå°ºå¯¸
```python
âœ… æ”¯æŒï¼š512 Ã— 512
âŒ ä¸æ”¯æŒï¼šä»»æ„åŠ¨æ€å°ºå¯¸
```

#### åŸå› 
- æ¨¡å‹å†…éƒ¨åŒ…å«å›ºå®šå°ºå¯¸çš„ `torch.nn.functional.interpolate` æ“ä½œ
- ONNX å¯¼å‡ºæ—¶åˆ†è¾¨ç‡è¢«ç¡¬ç¼–ç åˆ°è®¡ç®—å›¾ä¸­

#### è§£å†³æ–¹æ¡ˆ

**æ–¹æ¡ˆ Aï¼šå¤–éƒ¨ Resizeï¼ˆæ¨èï¼‰**
```python
# è¾“å…¥ç«¯ Resize
input_img = cv2.resize(original_img, (512, 512))
# ... æ¨ç† ...
# è¾“å‡ºç«¯ Resize å›åŸå°ºå¯¸
alpha = cv2.resize(alpha_512, (orig_w, orig_h))
```

**æ–¹æ¡ˆ Bï¼šå¤šæ¨¡å‹ç­–ç•¥ï¼ˆå·¥ç¨‹åŒ–æ–¹æ¡ˆï¼‰**
```python
# å¯¼å‡ºä¸åŒåˆ†è¾¨ç‡çš„æ¨¡å‹
models = {
    (512, 512): "matanyone_512.onnx",
    (640, 384): "matanyone_640x384.onnx",
    (1024, 1024): "matanyone_1024.onnx"
}

# æ ¹æ®è¾“å…¥é€‰æ‹©æ¨¡å‹
model = select_model(input_resolution)
```

---

### 2ï¸âƒ£ Batch Size æ”¯æŒ

#### åŠ¨æ€ Batch
```python
âœ… æ”¯æŒï¼šä»»æ„ batch_size (1, 2, 4, 8, ...)
```

#### æ‰¹å¤„ç†ç¤ºä¾‹
```python
# å‡†å¤‡ 4 å¼ å›¾åƒ
batch_images = []
for img_path in image_paths:
    img = preprocess(cv2.imread(img_path))  # â†’ (3, 512, 512)
    batch_images.append(img)

# åˆå¹¶ä¸º batch
batch_tensor = np.stack(batch_images, axis=0)  # â†’ (4, 3, 512, 512)

# æ‰¹é‡æ¨ç†
inputs = {
    'image': batch_tensor,
    'ref_sensory': np.zeros((4, 1, 256, 32, 32), dtype=np.float32),
    'ref_mask': np.zeros((4, 1, 512, 512), dtype=np.float32)
}
outputs = session.run(None, inputs)

# è¾“å‡ºä¹Ÿæ˜¯æ‰¹é‡çš„
alpha_batch = outputs[0]  # shape: (4, 2, 512, 512)
```

#### æ€§èƒ½ä¼˜åŒ–
- ğŸ“ˆ **ååé‡æå‡**ï¼šBatch=4 æ¯”å•å¼ æ¨ç†å¿« ~2-3 å€
- âš ï¸ **å†…å­˜å ç”¨**ï¼šæ˜¾å­˜å ç”¨ä¸ batch size æˆæ­£æ¯”
- ğŸ¯ **æ¨èé…ç½®**ï¼šGPU ä½¿ç”¨ batch=4~8ï¼ŒCPU ä½¿ç”¨ batch=1

---

### 3ï¸âƒ£ ç¡¬ä»¶è¦æ±‚

#### æœ€ä½é…ç½®
| ç»„ä»¶ | è§„æ ¼ |
|------|------|
| **CPU** | 4 æ ¸ @ 2.5GHz |
| **å†…å­˜** | 4 GB RAM |
| **æ¨ç†é€Ÿåº¦** | ~200 ms/frame |

#### æ¨èé…ç½®ï¼ˆGPUï¼‰
| ç»„ä»¶ | è§„æ ¼ |
|------|------|
| **GPU** | NVIDIA GTX 1660 æˆ–æ›´é«˜ |
| **æ˜¾å­˜** | 4 GB VRAM |
| **CUDA** | 11.0 æˆ–æ›´é«˜ |
| **cuDNN** | 8.0 æˆ–æ›´é«˜ |
| **æ¨ç†é€Ÿåº¦** | ~15-30 ms/frame |

#### é«˜æ€§èƒ½é…ç½®
| ç»„ä»¶ | è§„æ ¼ |
|------|------|
| **GPU** | NVIDIA RTX 3090 / 4090 |
| **æ˜¾å­˜** | 12 GB+ VRAM |
| **æ¨ç†é€Ÿåº¦** | ~5-10 ms/frame |

---

### 4ï¸âƒ£ ä¾èµ–ç¯å¢ƒ

#### Python ç¯å¢ƒ
```bash
Python >= 3.8
```

#### æ ¸å¿ƒä¾èµ–
```bash
pip install onnxruntime-gpu==1.16.0  # GPU ç‰ˆæœ¬
# æˆ–
pip install onnxruntime==1.16.0     # CPU ç‰ˆæœ¬

pip install opencv-python>=4.8.0
pip install numpy>=1.24.0
```

#### éªŒè¯å®‰è£…
```python
import onnxruntime as ort

# æ£€æŸ¥å¯ç”¨è®¾å¤‡
print("Available providers:", ort.get_available_providers())

# åº”è¯¥åŒ…å«ï¼š
# ['CUDAExecutionProvider', 'CPUExecutionProvider'] (GPU ç‰ˆæœ¬)
# ['CPUExecutionProvider'] (CPU ç‰ˆæœ¬)
```

---

## ğŸš€ å®Œæ•´æ¨ç†ç¤ºä¾‹

### å•å¸§æ¨ç†
```python
import cv2
import numpy as np
import onnxruntime as ort

# 1. åŠ è½½æ¨¡å‹
session = ort.InferenceSession(
    "matanyone_fixed.onnx",
    providers=['CUDAExecutionProvider', 'CPUExecutionProvider']
)

# 2. è¯»å–å›¾åƒ
img_bgr = cv2.imread("input.jpg")
orig_h, orig_w = img_bgr.shape[:2]

# 3. é¢„å¤„ç†
img_resized = cv2.resize(img_bgr, (512, 512))
img_rgb = cv2.cvtColor(img_resized, cv2.COLOR_BGR2RGB)
img_tensor = img_rgb.astype(np.float32) / 255.0
img_tensor = np.transpose(img_tensor, (2, 0, 1))[np.newaxis, ...]

# 4. å‡†å¤‡è¾“å…¥
inputs = {
    'image': img_tensor,
    'ref_sensory': np.zeros((1, 1, 256, 32, 32), dtype=np.float32),
    'ref_mask': np.zeros((1, 1, 512, 512), dtype=np.float32)
}

# 5. æ¨ç†
outputs = session.run(None, inputs)
alpha_output = outputs[0]

# 6. æå–å‰æ™¯
foreground_prob = alpha_output[0, 1]
alpha = cv2.resize(foreground_prob, (orig_w, orig_h))

# 7. åˆæˆç»¿å¹•
alpha_3c = np.stack([alpha, alpha, alpha], axis=-1)
green_bg = np.zeros_like(img_bgr, dtype=np.float32)
green_bg[:, :] = (0, 255, 0)

result = img_bgr.astype(np.float32) * alpha_3c + green_bg * (1 - alpha_3c)
result = np.clip(result, 0, 255).astype(np.uint8)

# 8. ä¿å­˜ç»“æœ
cv2.imwrite("output.jpg", result)
```

---

### è§†é¢‘å¤„ç†
```python
import cv2
import numpy as np
import onnxruntime as ort

# åˆå§‹åŒ–
session = ort.InferenceSession("matanyone_fixed.onnx", 
                               providers=['CUDAExecutionProvider'])
cap = cv2.VideoCapture("input.mp4")
fourcc = cv2.VideoWriter_fourcc(*'mp4v')
out = cv2.VideoWriter("output.mp4", fourcc, 30.0, 
                      (int(cap.get(3)), int(cap.get(4))))

# åˆå§‹åŒ–å‚è€ƒå¸§ï¼ˆåªåœ¨é¦–å¸§ï¼‰
ref_sensory = np.zeros((1, 1, 256, 32, 32), dtype=np.float32)
ref_mask = np.zeros((1, 1, 512, 512), dtype=np.float32)

frame_count = 0
while True:
    ret, frame = cap.read()
    if not ret:
        break
    
    orig_h, orig_w = frame.shape[:2]
    
    # é¢„å¤„ç†
    img_resized = cv2.resize(frame, (512, 512))
    img_rgb = cv2.cvtColor(img_resized, cv2.COLOR_BGR2RGB)
    img_tensor = img_rgb.astype(np.float32) / 255.0
    img_tensor = np.transpose(img_tensor, (2, 0, 1))[np.newaxis, ...]
    
    # æ¨ç†
    inputs = {
        'image': img_tensor,
        'ref_sensory': ref_sensory,
        'ref_mask': ref_mask
    }
    outputs = session.run(None, inputs)
    alpha_output = outputs[0]
    
    # å¯é€‰ï¼šæ›´æ–° ref_maskï¼ˆå¯ç”¨é€å¸§æ›´æ–°ï¼‰
    # ref_mask = alpha_output[:, 1:2, :, :]
    
    # åå¤„ç†
    foreground_prob = alpha_output[0, 1]
    alpha = cv2.resize(foreground_prob, (orig_w, orig_h))
    alpha_3c = np.stack([alpha, alpha, alpha], axis=-1)
    
    # åˆæˆ
    green_bg = np.zeros_like(frame, dtype=np.float32)
    green_bg[:, :] = (0, 255, 0)
    result = frame.astype(np.float32) * alpha_3c + green_bg * (1 - alpha_3c)
    result = np.clip(result, 0, 255).astype(np.uint8)
    
    out.write(result)
    frame_count += 1
    
    if frame_count % 30 == 0:
        print(f"Processed {frame_count} frames")

cap.release()
out.release()
print(f"Total frames processed: {frame_count}")
```

---

## âš ï¸ å¸¸è§é—®é¢˜ä¸è§£å†³æ–¹æ¡ˆ

### é—®é¢˜ 1ï¼šè¾“å‡ºå…¨é»‘æˆ–å…¨ç™½

**åŸå› ï¼š**
- è¾“å…¥å€¼åŸŸé”™è¯¯ï¼ˆæœªå½’ä¸€åŒ–æˆ–å½’ä¸€åŒ–é”™è¯¯ï¼‰
- BGR/RGB é€šé“é¡ºåºé”™è¯¯

**è§£å†³æ–¹æ¡ˆï¼š**
```python
# æ£€æŸ¥è¾“å…¥èŒƒå›´
print(f"Input range: [{img_tensor.min():.3f}, {img_tensor.max():.3f}]")
# åº”è¯¥æ˜¯ [0.0, 1.0]

# ç¡®è®¤å·²è½¬æ¢ä¸º RGB
img_rgb = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2RGB)
```

---

### é—®é¢˜ 2ï¼šè¾¹ç¼˜æœ‰é”¯é½¿

**åŸå› ï¼š**
- Resize æ’å€¼æ–¹æ³•ä¸å½“
- ç¼ºå°‘è¾¹ç¼˜ç¾½åŒ–

**è§£å†³æ–¹æ¡ˆï¼š**
```python
# ä½¿ç”¨é«˜è´¨é‡æ’å€¼
alpha = cv2.resize(foreground_prob, (orig_w, orig_h), 
                   interpolation=cv2.INTER_CUBIC)

# è¾¹ç¼˜ç¾½åŒ–
alpha = cv2.GaussianBlur(alpha, (5, 5), 2.0)
```

---

### é—®é¢˜ 3ï¼šè§†é¢‘æŠ–åŠ¨/é—ªçƒ

**åŸå› ï¼š**
- é€å¸§æ›´æ–° `ref_mask` å¯¼è‡´è¯¯å·®ç´¯ç§¯
- ç¼ºå°‘æ—¶åºå¹³æ»‘

**è§£å†³æ–¹æ¡ˆï¼š**
```python
# æ–¹æ¡ˆ Aï¼šå›ºå®šé¦–å¸§å‚è€ƒ
ref_mask = np.zeros((1, 1, 512, 512), dtype=np.float32)  # ä¸æ›´æ–°

# æ–¹æ¡ˆ Bï¼šæ—¶åºå¹³æ»‘
alpha_smooth = 0.7 * alpha_prev + 0.3 * alpha_current
```

---

### é—®é¢˜ 4ï¼šCUDA å†…å­˜ä¸è¶³

**åŸå› ï¼š**
- Batch size è¿‡å¤§
- æ˜¾å­˜è¢«å…¶ä»–ç¨‹åºå ç”¨

**è§£å†³æ–¹æ¡ˆï¼š**
```python
# å‡å° batch size
batch_size = 1  # æˆ– 2

# æ¸…ç† GPU ç¼“å­˜ï¼ˆPyTorch é¡¹ç›®ï¼‰
import torch
torch.cuda.empty_cache()

# ä½¿ç”¨ CPU æ¨¡å¼
session = ort.InferenceSession("matanyone_fixed.onnx", 
                               providers=['CPUExecutionProvider'])
```

---

### é—®é¢˜ 5ï¼šæ¨ç†é€Ÿåº¦æ…¢

**åŸå› ï¼š**
- ä½¿ç”¨ CPU æ¨ç†
- æœªå¯ç”¨ TensorRT

**è§£å†³æ–¹æ¡ˆï¼š**
```python
# ç¡®è®¤ä½¿ç”¨ GPU
providers = session.get_providers()
print("Active provider:", providers[0])  # åº”è¯¥æ˜¯ 'CUDAExecutionProvider'

# å®‰è£… TensorRT åŠ é€Ÿï¼ˆå¯é€‰ï¼‰
pip install onnxruntime-gpu-tensorrt
```

---

## ğŸ“Š æ€§èƒ½åŸºå‡†æµ‹è¯•

### æµ‹è¯•ç¯å¢ƒ
- **GPU:** NVIDIA RTX 3090 (24GB)
- **CPU:** Intel i9-12900K
- **åˆ†è¾¨ç‡:** 512Ã—512
- **Framework:** ONNX Runtime 1.16.0

### æ¨ç†é€Ÿåº¦

| Batch Size | GPU (ms/batch) | CPU (ms/batch) | ååé‡ (FPS) |
|------------|----------------|----------------|--------------|
| 1 | 8.5 ms | 185 ms | 117 / 5.4 |
| 4 | 22 ms | 720 ms | 181 / 5.5 |
| 8 | 40 ms | 1440 ms | 200 / 5.5 |

### å†…å­˜å ç”¨

| Batch Size | GPU æ˜¾å­˜ | ç³»ç»Ÿå†…å­˜ |
|------------|----------|----------|
| 1 | 1.2 GB | 0.5 GB |
| 4 | 2.8 GB | 1.2 GB |
| 8 | 5.2 GB | 2.4 GB |

---

## ğŸ“š å‚è€ƒèµ„æ–™

### ç›¸å…³è®ºæ–‡
- [Matting Anything]
- [Robust Video Matting]
- [Background Matting v2]

### å®˜æ–¹èµ„æº
- **GitHub:** [MatAnyone Repository]
- **Paper:** [arXiv Link]
- **Demo:** [Online Demo]

### ç¤¾åŒºæ”¯æŒ
- **Issues:** [GitHub Issues]
- **Discussions:** [GitHub Discussions]
- **Discord:** [Community Server]

---

## ğŸ“ æ›´æ–°æ—¥å¿—

### Version 1.0.0 (2024-XX-XX)
- âœ… é¦–æ¬¡å‘å¸ƒ ONNX å›ºå®šç‰ˆæœ¬
- âœ… æ”¯æŒ 512Ã—512 åˆ†è¾¨ç‡
- âœ… æ”¯æŒ CUDA/CPU æ¨ç†
- âœ… æ”¯æŒåŠ¨æ€ batch size

### è®¡åˆ’ä¸­çš„åŠŸèƒ½
- â³ å¤šåˆ†è¾¨ç‡æ”¯æŒ
- â³ TensorRT INT8 é‡åŒ–ç‰ˆæœ¬
- â³ Web å‰ç«¯ (ONNX.js)
- â³ ç§»åŠ¨ç«¯éƒ¨ç½² (ONNX Mobile)

---
 
---

## ğŸ“„ è®¸å¯è¯

æœ¬æ¨¡å‹éµå¾ª [MIT License / Apache 2.0 / å…¶ä»–] åè®®ã€‚

è¯¦æƒ…è¯·å‚é˜… [LICENSE](LICENSE) æ–‡ä»¶ã€‚

---

<div align="center">
  <strong>MatAnyone ONNX - å¼€ç®±å³ç”¨çš„é«˜æ€§èƒ½æŠ å›¾è§£å†³æ–¹æ¡ˆ</strong>
  <br>
  <sub>Built with â¤ï¸ by the MatAnyone Team</sub>
</div>
```

---

## ä½¿ç”¨è¯´æ˜

è¿™ä¸ª Markdown æ–‡æ¡£åŒ…å«ï¼š

### âœ… å®Œæ•´å†…å®¹
1. **æ¨¡å‹æ¦‚è¿°** - åŸºæœ¬ä¿¡æ¯å’Œèƒ½åŠ›ä»‹ç»
2. **è¾“å…¥è§„æ ¼** - è¯¦ç»†çš„ä¸‰ä¸ªè¾“å…¥å‚æ•°è¯´æ˜
3. **è¾“å‡ºè§„æ ¼** - Alpha é€šé“çš„æå–å’Œä½¿ç”¨
4. **ç‰¹å®šè¦æ±‚** - åˆ†è¾¨ç‡ã€ç¡¬ä»¶ã€ç¯å¢ƒç­‰é™åˆ¶
5. **ä»£ç ç¤ºä¾‹** - å•å¸§å’Œè§†é¢‘å¤„ç†çš„å®Œæ•´ä»£ç 
6. **å¸¸è§é—®é¢˜** - 5 ä¸ªå…¸å‹é—®é¢˜çš„è§£å†³æ–¹æ¡ˆ
7. **æ€§èƒ½åŸºå‡†** - æµ‹è¯•æ•°æ®å’Œå‚è€ƒæŒ‡æ ‡

### ğŸ“‹ å¯ä»¥ç›´æ¥ï¼š
- ä¿å­˜ä¸º `MODEL_SPECIFICATION.md`
- æ”¾åœ¨é¡¹ç›®æ ¹ç›®å½•
- ä½œä¸º API æ–‡æ¡£ä½¿ç”¨
- å‘å¸ƒåˆ° GitHub/GitLab

### ğŸ¨ ç‰¹ç‚¹ï¼š
- âœ… ä¸“ä¸šæ ¼å¼ï¼ˆè¡¨æ ¼ã€ä»£ç å—ã€emojiï¼‰
- âœ… å®ç”¨ç¤ºä¾‹ï¼ˆå¯ç›´æ¥è¿è¡Œï¼‰
- âœ… è¯¦ç»†è¯´æ˜ï¼ˆé¿å…å¸¸è§é”™è¯¯ï¼‰
- âœ… å®Œæ•´ç»“æ„ï¼ˆä»å®‰è£…åˆ°éƒ¨ç½²ï¼‰

 
